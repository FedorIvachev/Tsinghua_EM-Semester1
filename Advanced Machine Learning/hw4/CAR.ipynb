{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import math\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    " class ActorCritic(nn.Module):\n",
    "    def __init__(self, env, hid_size=24):\n",
    "        super(ActorCritic, self).__init__()\n",
    "        self.env = env\n",
    "        self.shape_size = env.observation_space.shape[0]\n",
    "        self.hid_size = hid_size\n",
    "        self.act_size = env.action_space.shape[0]\n",
    "        self.FC_1 = nn.Linear(self.shape_size, self.hid_size)\n",
    "        self.FC_2 = nn.Linear(self.hid_size, self.act_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.FC_1(x))\n",
    "        x = F.tanh(self.FC_2(x))\n",
    "        return x.cpu().data\n",
    "        \n",
    "    def evaluate(self, weights, gamma=0.98, max_t=6000):\n",
    "        self.set_weights(weights)\n",
    "        episode_return = 0.0\n",
    "        state = self.env.reset()\n",
    "        for t in range(max_t):\n",
    "            state = torch.from_numpy(state).float().to(device)\n",
    "            action = self.forward(state)\n",
    "            state, reward, done, _ = self.env.step(action)\n",
    "            episode_return += reward * math.pow(gamma, t)\n",
    "            if done:\n",
    "                break\n",
    "        return episode_return\n",
    "        \n",
    "    def set_weights(self, weights):\n",
    "        shape_size = self.shape_size\n",
    "        hid_size = self.hid_size\n",
    "        act_size = self.act_size\n",
    "        FC_1_end = (shape_size*hid_size)+hid_size\n",
    "        FC_1_W = torch.from_numpy(weights[:shape_size*hid_size].reshape(shape_size, hid_size))\n",
    "        FC_1_b = torch.from_numpy(weights[shape_size*hid_size:FC_1_end])\n",
    "        FC_2_W = torch.from_numpy(weights[FC_1_end:FC_1_end+(hid_size*act_size)].reshape(hid_size, act_size))\n",
    "        FC_2_b = torch.from_numpy(weights[FC_1_end+(hid_size*act_size):])\n",
    "        self.FC_1.weight.data.copy_(FC_1_W.view_as(self.FC_1.weight.data))\n",
    "        self.FC_1.bias.data.copy_(FC_1_b.view_as(self.FC_1.bias.data))\n",
    "        self.FC_2.weight.data.copy_(FC_2_W.view_as(self.FC_2.weight.data))\n",
    "        self.FC_2.bias.data.copy_(FC_2_b.view_as(self.FC_2.bias.data))\n",
    "    \n",
    "    def get_weights_dim(self):\n",
    "        return (self.shape_size+1)*self.hid_size + (self.hid_size+1)*self.act_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "\n",
    "env = gym.make('MountainCarContinuous-v0')\n",
    "env.seed(111)\n",
    "np.random.seed(111)\n",
    "\n",
    "model = ActorCritic(env).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cem(max_episodes=3000, max_t=1000, gamma=0.98, print_interval=20, pp_sz=50, top=0.23, sigma=0.5):\n",
    "    scores_deque = deque(maxlen=100)\n",
    "    scores = []\n",
    "    best_weight = sigma*np.random.randn(model.get_weights_dim())\n",
    "\n",
    "    for n_epi in range(1, max_episodes + 1):\n",
    "        weights_pop = [best_weight + (sigma*np.random.randn(model.get_weights_dim())) for i in range(pp_sz)]\n",
    "        rewards = np.array([model.evaluate(weights, gamma, max_t) for weights in weights_pop])\n",
    "\n",
    "        elite_idxs = rewards.argsort()[-pp_sz*top:]\n",
    "        elite_weights = [weights_pop[i] for i in elite_idxs]\n",
    "        best_weight = np.array(elite_weights).mean(axis=0)\n",
    "\n",
    "        reward = model.evaluate(best_weight, gamma=1.0)\n",
    "        scores_deque.append(reward)\n",
    "        scores.append(reward)\n",
    "        \n",
    "        if n_epi % print_interval == 0:\n",
    "            print('CartPole-v1 # of episode : {}\\t, avg score : {:.2f}'.format(n_epi, np.mean(scores_deque)))\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MountainCar-v0 # of episode : 200\t, avg score : -5.85\n",
      "MountainCar-v0 # of episode : 400\t, avg score : -0.84\n",
      "MountainCar-v0 # of episode : 600\t, avg score : 2.10\n",
      "MountainCar-v0 # of episode : 800\t, avg score : 10.15\n",
      "MountainCar-v0 # of episode : 1000\t, avg score : 13.65\n",
      "MountainCar-v0 # of episode : 1200\t, avg score : 23.90\n",
      "MountainCar-v0 # of episode : 1400\t, avg score : 45.34\n",
      "MountainCar-v0 # of episode : 1600\t, avg score : 57.37\n",
      "MountainCar-v0 # of episode : 1800\t, avg score : 75.27\n",
      "MountainCar-v0 # of episode : 2000\t, avg score : 82.39\n",
      "MountainCar-v0 # of episode : 2200\t, avg score : 89.20\n",
      "MountainCar-v0 # of episode : 2400\t, avg score : 90.54\n",
      "MountainCar-v0 # of episode : 2600\t, avg score : 91.40\n",
      "MountainCar-v0 # of episode : 2800\t, avg score : 91.56\n",
      "MountainCar-v0 # of episode : 3000\t, avg score : 92.01\n"
     ]
    }
   ],
   "source": [
    "scores = cem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
